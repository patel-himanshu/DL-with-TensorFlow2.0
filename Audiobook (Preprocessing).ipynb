{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the data from the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = np.loadtxt('Audiobooks_data.csv', delimiter = ',')\n",
    "\n",
    "inputs_all = csv_data[:, 1:-1] # Excluding \"id\" and \"targets\"\n",
    "targets_all = csv_data[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our data set, the number of `targets = 0` > number of `targets = 1` <br>\n",
    "Hence, we will balance the targets, such that both the targets are equal in number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2237"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_target_one = int(np.sum(targets_all)) # Typecasting into \"int\", as the sum is a \"float\"\n",
    "num_target_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_counter = 0\n",
    "indices_to_remove = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14084"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_all.shape[0] \n",
    "# Gives the total number of data entries \n",
    "# (or simply the total number of rows in our data set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find the indices of extra occurences of 0, so that after \n",
    "# deleting them, the priors get balanced\n",
    "\n",
    "# shape[0] denotes the elements present in axis = 0 (x-axis) or rows\n",
    "for i in range(targets_all.shape[0]): \n",
    "    if (targets_all[i] == 0):\n",
    "        zero_counter += 1\n",
    "        if (zero_counter > num_target_one):\n",
    "            indices_to_remove.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing extra input values\n",
    "inputs_equal_priors = np.delete(inputs_all, indices_to_remove, axis = 0) \n",
    "\n",
    "# Removing extra target values\n",
    "targets_equal_priors = np.delete(targets_all, indices_to_remove, axis = 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All data of a particular variable get standardized\n",
    "scaled_inputs = preprocessing.scale(inputs_equal_priors) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our targets comprise of only 0 or 1, so no need to standardize the \"targets\" data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating an \"array\" that the indices of all the remaining \n",
    "# entries of our data set\n",
    "shuffled_indices = np.arange(targets_equal_priors.shape[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(shuffled_indices) # Shuffling the indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`shuffling_done = np.random.shuffle(shuffled_indices)` cannot do in this way. <br>\n",
    "Abovementioned code would return `None`, not the shuffled indices. <br>\n",
    "`np.random.shuffle(array)` does inplace shuffling on the passed array itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_inputs = scaled_inputs[shuffled_indices]\n",
    "shuffled_targets = targets_equal_priors[shuffled_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting it into training, validation and testing data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4474\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(shuffled_inputs.shape[0]) # Number of rows (X-axis)\n",
    "print(shuffled_inputs.shape[1]) # Number of columns (Y-axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_count = shuffled_inputs.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 75-15-10 split for training, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 75% data being kept for training\n",
    "training_count = int(0.75 * samples_count)\n",
    "\n",
    "# 15% data being kept for validation\n",
    "validation_count = int(0.15 * samples_count) \n",
    "\n",
    "# Remaining data being kept for testing\n",
    "testing_count = samples_count - training_count - validation_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3355\n",
      "671\n",
      "448\n"
     ]
    }
   ],
   "source": [
    "print(training_count)\n",
    "print(validation_count)\n",
    "print(testing_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training inputs\n",
    "train_inputs = shuffled_inputs[0:training_count] \n",
    "\n",
    "# Creating training targets\n",
    "train_targets = shuffled_targets[0:training_count] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating validation inputs\n",
    "validation_inputs = shuffled_inputs[training_count:training_count + validation_count] \n",
    "\n",
    "# Creating validation targets\n",
    "validation_targets = shuffled_targets[training_count:training_count + validation_count] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating testing inputs\n",
    "test_inputs = shuffled_inputs[training_count + validation_count:] \n",
    "\n",
    "# Creating testing targets\n",
    "test_targets = shuffled_targets[training_count + validation_count:] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the balance of resultant data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49538002980625934\n",
      "0.4858420268256334\n",
      "0.5558035714285714\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(train_targets) / training_count)\n",
    "print(np.sum(validation_targets) / validation_count)\n",
    "print(np.sum(test_targets) / testing_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As all data set splits are close to 50% priors (i.e. they have 50% targets as `0` and 50% targets as `1`), we can say that our data set splits are balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the data in .npz file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('Audiobooks_training', inputs = train_inputs, targets = train_targets)\n",
    "np.savez('Audiobooks_validation', inputs = validation_inputs, targets = validation_targets)\n",
    "np.savez('Audiobooks_testing', inputs = test_inputs, targets = test_targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
